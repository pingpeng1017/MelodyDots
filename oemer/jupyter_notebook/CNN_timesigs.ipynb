{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6194f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import augly.image as imaugs\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from oemer.bbox import get_bbox, merge_nearby_bbox, draw_bounding_boxes, rm_merge_overlap_bbox\n",
    "from oemer.build_label import find_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bd840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_WIDTH = 40\n",
    "TARGET_HEIGHT = 70\n",
    "DISTANCE = 10\n",
    "\n",
    "DATASET_PATH = \"./ds2_dense/segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d17557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect(color, out_path, samples=500):\n",
    "    out_path = Path(out_path)\n",
    "    if not out_path.exists():\n",
    "        out_path.mkdir()\n",
    "\n",
    "    cur_samples = 0\n",
    "    add_space = 10\n",
    "    idx = 0\n",
    "    while cur_samples < samples:\n",
    "        arr = find_example(DATASET_PATH, color)\n",
    "        if arr is None:\n",
    "            continue\n",
    "        arr[arr!=200] = 0\n",
    "        boxes = get_bbox(arr)\n",
    "        if len(boxes) > 1:\n",
    "            boxes = merge_nearby_bbox(boxes, DISTANCE)\n",
    "        boxes = rm_merge_overlap_bbox(boxes)\n",
    "        for box in boxes:\n",
    "            if idx >= samples:\n",
    "                break\n",
    "            print(f\"{idx+1}/{samples}\", end='\\r')\n",
    "            patch = arr[box[1]-add_space:box[3]+add_space, box[0]-add_space:box[2]+add_space]\n",
    "            ratio = random.choice(np.arange(0.6, 1.3, 0.1))\n",
    "            tar_w = int(ratio * patch.shape[1])\n",
    "            tar_h = int(ratio * patch.shape[0])\n",
    "            img = imaugs.resize(Image.fromarray(patch.astype(np.uint8)), width=tar_w, height=tar_h)\n",
    "\n",
    "            seed = random.randint(0, 1000)\n",
    "            img = imaugs.perspective_transform(img, seed=seed, sigma=3)\n",
    "            img = np.where(np.array(img)>0, 255, 0)\n",
    "            Image.fromarray(patch.astype(np.uint8)).save(out_path / f\"{idx}.png\")\n",
    "            idx += 1\n",
    "\n",
    "        cur_samples += len(boxes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ce460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(samples=500):\n",
    "    color_map = {\n",
    "#         74: \"sharp\",\n",
    "#         70: \"flat\",\n",
    "#         72: \"natural\",\n",
    "# #         97: 'rest_whole',\n",
    "# #         98: 'rest_half',\n",
    "# #         99: 'rest_quarter',\n",
    "# #         100: 'rest_8th',\n",
    "# #         101: 'rest_16th',\n",
    "# #         102: 'rest_32nd',\n",
    "# #         103: 'rest_64th',\n",
    "# #         104: 'rest_128th'\n",
    "#         # 10: 'gclef',\n",
    "#         # 13: 'fclef',\n",
    "        # 추가: time signature에 해당하는 데이터\n",
    "        21: 'timesig_0',\n",
    "        22: 'timesig_1',\n",
    "        23: 'timesig_2',\n",
    "        24: 'timesig_3',\n",
    "        25: 'timesig_4',\n",
    "        26: 'timesig_5',\n",
    "        27: 'timesig_6',\n",
    "        28: 'timesig_7',\n",
    "        29: 'timesig_8',\n",
    "        30: 'timesig_9',\n",
    "        33: 'timesig_4_4',\n",
    "        34: 'timesig_2_2',\n",
    "    }\n",
    "    \n",
    "    for color, name in color_map.items():\n",
    "        print('Current', name)\n",
    "        _collect(color, f\"./ds2_dense/train_data/{name}\", samples=samples)\n",
    "        _collect(color, f\"./ds2_dense/val_data/{name}\", samples=samples)  # 검증 데이터 생성 및 저장\n",
    "        _collect(color, f\"./ds2_dense/test_data/{name}\", samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a23791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(folders):\n",
    "    class_map = {idx: Path(ff).name for idx, ff in enumerate(folders)}\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    val_data = []  # 추가: 검증 데이터\n",
    "    val_labels = []  # 추가: 검증 데이터\n",
    "    samples = None\n",
    "    print(\"Loading data\")\n",
    "    for cidx, folder in enumerate(folders):\n",
    "        folder = Path(folder)\n",
    "        idx = 0\n",
    "        for ff in folder.glob('*.png'):\n",
    "            if samples is not None and idx >= samples:\n",
    "                break\n",
    "            img = Image.open(ff).resize((TARGET_WIDTH, TARGET_HEIGHT))\n",
    "            arr = np.array(img)\n",
    "            if idx % 5 == 0:  # 추가: 검증 데이터를 위해 1/5 비율로 분할\n",
    "                val_data.append(arr)\n",
    "                val_labels.append(cidx)\n",
    "            else:\n",
    "                train_data.append(arr)\n",
    "                train_labels.append(cidx)\n",
    "            idx += 1\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    val_data = np.array(val_data)  # 추가: 검증 데이터\n",
    "    val_labels = np.array(val_labels)  # 추가: 검증 데이터\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(len(folders), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=20, batch_size=32)  # 수정: 검증 데이터 사용\n",
    "    return model, class_map, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade8246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tf(model, folders):\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    print(\"Loading data\")\n",
    "    for cidx, folder in enumerate(folders):\n",
    "        folder = Path(folder)\n",
    "        files = list(folder.iterdir())\n",
    "        random.shuffle(files)\n",
    "        for ff in files:\n",
    "            img = Image.open(ff).resize((TARGET_WIDTH, TARGET_HEIGHT))\n",
    "            arr = np.array(img)\n",
    "            test_x.append(arr)\n",
    "            test_y.append(cidx)\n",
    "\n",
    "    test_x = np.array(test_x)[..., np.newaxis]\n",
    "    test_y = np.array(test_y)\n",
    "    test_result = []\n",
    "    batch_size = 32\n",
    "    for idx in range(0, len(test_x), batch_size):\n",
    "        data = test_x[idx:idx+batch_size]\n",
    "        pred = model.predict(data)\n",
    "        pidx = np.argmax(pred, axis=-1)\n",
    "        test_result.extend(list(pidx))\n",
    "\n",
    "    test_result = np.array(test_result)\n",
    "    tp = test_result[test_result==test_y].size\n",
    "    acc = tp / len(test_y)\n",
    "    print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5678bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(region, model_name):\n",
    "    if np.max(region) == 1:\n",
    "        region *= 255\n",
    "    m_info = pickle.load(open(f\"sklearn_models/{model_name}.model\", \"rb\"))\n",
    "    model = m_info['model']\n",
    "    w = m_info['w']\n",
    "    h = m_info['h']\n",
    "    region = Image.fromarray(region.astype(np.uint8)).resize((w, h))\n",
    "    pred = model.predict(np.array(region).reshape(1, -1))\n",
    "    return m_info['class_map'][pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1acb9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current timesig_0\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_1\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_2\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_3\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_4\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_5\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_6\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_7\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_8\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_9\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_4_4\n",
      "500/500\n",
      "500/500\n",
      "500/500\n",
      "Current timesig_2_2\n",
      "500/500\n",
      "500/500\n",
      "500/500\n"
     ]
    }
   ],
   "source": [
    "samples = 500\n",
    "\n",
    "collect_data(samples=samples)\n",
    "\n",
    "\n",
    "folders = [\"timesig_0\", \"timesig_1\", \"timesig_2\", \"timesig_3\", \"timesig_4\", \"timesig_5\", \"timesig_6\", \"timesig_7\", \"timesig_8\", \"timesig_9\", \"timesig_4_4\", \"timesig_2_2\"]\n",
    "model_name = \"timesigs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8a0a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 9s 50ms/step - loss: 0.3986 - accuracy: 0.8756 - val_loss: 0.1288 - val_accuracy: 0.9325\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1516 - accuracy: 0.9383 - val_loss: 0.1009 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1222 - accuracy: 0.9456 - val_loss: 0.0896 - val_accuracy: 0.9608\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1100 - accuracy: 0.9535 - val_loss: 0.1007 - val_accuracy: 0.9492\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1024 - accuracy: 0.9542 - val_loss: 0.0907 - val_accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1035 - accuracy: 0.9552 - val_loss: 0.0893 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1078 - accuracy: 0.9535 - val_loss: 0.0923 - val_accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 0.1114 - accuracy: 0.9527 - val_loss: 0.0976 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 0.1138 - accuracy: 0.9498 - val_loss: 0.0927 - val_accuracy: 0.9608\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.1017 - accuracy: 0.9544 - val_loss: 0.0975 - val_accuracy: 0.9492\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.1014 - accuracy: 0.9513 - val_loss: 0.0956 - val_accuracy: 0.9492\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.0999 - accuracy: 0.9544 - val_loss: 0.0921 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.1026 - accuracy: 0.9529 - val_loss: 0.0892 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1074 - accuracy: 0.9525 - val_loss: 0.0924 - val_accuracy: 0.9608\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1032 - accuracy: 0.9515 - val_loss: 0.0931 - val_accuracy: 0.9608\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1038 - accuracy: 0.9506 - val_loss: 0.0950 - val_accuracy: 0.9608\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 0.1105 - accuracy: 0.9531 - val_loss: 0.1049 - val_accuracy: 0.9608\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.0999 - accuracy: 0.9542 - val_loss: 0.1036 - val_accuracy: 0.9608\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 0.0994 - accuracy: 0.9560 - val_loss: 0.1068 - val_accuracy: 0.9608\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 10s 66ms/step - loss: 0.0999 - accuracy: 0.9560 - val_loss: 0.1068 - val_accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "model, class_map, history = train([f\"ds2_dense/train_data/{folder}\" for folder in folders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a159605",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 훈련 과정에서의 손실, 정확도, 검증 손실, 검증 정확도 값을 가져옴\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련 과정에서의 손실, 정확도, 검증 손실, 검증 정확도 값을 가져옴\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# 그래프 생성 및 표시\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy, label='Training Accuracy', color='orange')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='purple')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7f35ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Accuracy:  0.9595\n"
     ]
    }
   ],
   "source": [
    "test_tf(model, [f\"ds2_dense/test_data/{folder}\" for folder in folders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f12a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'model': model, 'w': TARGET_WIDTH, 'h': TARGET_HEIGHT, 'class_map': class_map}\n",
    "pickle.dump(output, open(f\"sklearn_models/{model_name}.model\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oemer",
   "language": "python",
   "name": "oemer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
